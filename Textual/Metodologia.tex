\chapter{Metodologia}

A metodologia deste trabalho foi dividida em duas partes: A obtenção dos dados da câmera, bem como \textit{keypoints} e \textit{keyframes} partindo da câmera de um \textit{smartphone} utilizando um aplicativo de autoria própria, o \textit{PhotoGuide}; e a reconstrução do ambiente utilizando a ferramenta \textit{LSD-SLAM}. O \textit{PhotoGuide} não foi usado na segunda parte do projeto devido à baixa performance e do baixo suporte nativo da ferramenta \textit{OpenCV} para \textit{Android} fazendo a reconstrução 3D ser migrada do \textit{smartphone} para uma ferramenta \textit{desktop}.


\section{\textit{PhotoGuide}}

Desenvolvido para a plataforma \textit{Android}®, o \textit{PhotoGuide} \cite{PhotoGuide} teve como objetivo primário a reconstrução de ambientes à partir da câmera do dispositivo. O aplicativo utiliza diversos algoritmos providos pela biblioteca de terceiros \textit{OpenCV} \cite{OpenCV}. O objetivo do \textit{PhotoGuide} é, partindo do \textit{stream} da câmera ou recebendo um conjunto de imagens sequenciais, obter os quadros num intervalo pré-determinado e então enviar pares para serem processados utilizando o \textit{ORB}, retornando os \textit{keypoints} encontrados depois de filtrados, sendo inseridos num banco de dados no final do processo.  Primeiramente foi necessário obter os \textit{keypoints} da cena, e os algoritmos mais utilizados para isso são \textit{SIFT} e \textit{SURF}, mas infelizmente ambos são patenteados, o que nos obrigaria a lidar com a questão das patentes e permissão de uso. O \textit{ORB} e \textit{BRISK} são algoritmos para obter \textit{keypoints} e seus descritores, e foram desenvolvidos para terem um desempenho semelhante ao \textit{SIFT} e\textit{ SURF}, tornando-se assim a melhor escolha já que são de livre uso.

Primeiramente, os \textit{keypoints} são obtidos diretamente da câmera do aparelho, mas a taxa de captura usada foi 10\textit{FPS}, e passados (como imagens \textit{bitmap} e em pares) para o \textit{ORB}; então são processado os \textit{keypoints} e seus descritores, mas infelizmente é possível haver ruído na imagem e, portanto, ocasionando em falsos casamento entre uma imagem e outra. Para remover o máximo possível de falsos positivos, foram utilizadas três técnicas de refinamento, na ordem: \textit{Cross Check}, \textit{Ratio Filtering} e \textit{RANSAC}.

Ao executar o \textit{ORB} e \textit{BRISK}, são obtidas estruturas que possuem informações acerca do \textit{keypoint}, bem como informações sobre seu correspondente na segunda imagem. O \textit{Cross Check} consiste em rodar o algoritmo duas vezes, uma procurando pontos da primeira imagem na segunda, e outra vez procurando pontos da segunda imagem na primeira. Por fim, percorre ambos, verificando se para cada casamento da primeira lista, as informações batem com o casamento correspondente da segunda lista.

O \textit{Ratio Filtering} percorre a lista resultante, verificando se há mais de um casamento para cada \textit{keypoint}, já que o ideal é que cada \textit{keypoint} tenha apenas um único correspondente na segunda imagem. Ao encontrar mais de uma ocorrência, descarta os pontos mais distantes.

Por fim, a última filtragem é realizada com o \textit{RANSAC} \cite{RANSAC}. As comparações entre as imagens eram retornadas, e seus \textit{keypoints} armazenados num banco de dados, para futuro processamento. A Figura \ref{fig3:2} mostra um exemplo da execução do aplicativo:

\begin{figure}[H]
	\centering
		\includegraphics[width= \textwidth]{Imagens/figura3-2E4-4.png}
	\caption{\textit{Keypoints} encontrados e filtrados entre duas imagens.}
	\label{fig3:2}
\end{figure}

 
Foi adicionado ao aplicativo a opção de realizar a calibração da câmera com o auxílio da biblioteca \textit{OpenCV}, já que foi percebido que a distorção radial da câmera estava influenciando os resultados. A calibração da câmera, numa forma prática, consiste em fornecer um \textit{stream} da câmera ou sequência de fotos, contendo um padrão pré-definido. O \textit{OpenCV} fornece funções para calibrar a câmera de um dispositivo, necessitando das imagens capturadas do padrão, dentre as seguintes opções:

\begin{itemize}
	\item{Tabuleiro de xadrez na Figura \ref{fig3:3}}
	\item{Círculos alinhados assimetricamente na Figura \ref{fig3:4}}
	\item{Círculos alinhados simetricamente na Figura \ref{fig3:5}}
\end{itemize}

\begin{figure}[H]
\minipage{0.32\textwidth}
  \includegraphics[width=\linewidth]{Imagens/figura3-3E3-12.png}
  \caption{Tabuleiro de xadrez}\label{fig3:3}
\endminipage\hfill
\minipage{0.32\textwidth}
  \includegraphics[width=\linewidth]{Imagens/figura3-4.png}
  \caption{Círculos alinhados assimetricamente}\label{fig3:4}
\endminipage\hfill
\minipage{0.32\textwidth}
  \includegraphics[width=\linewidth]{Imagens/figura3-5.jpg}
  \caption{Círculos alinhados simetricamente}\label{fig3:5}
\endminipage
\end{figure}


\begin{figure}[H]
\minipage{0.49\textwidth}
  \includegraphics[width=\linewidth]{Imagens/figura3-6.jpg}
  \caption{Reconhecimento do tabuleiro de xadrez}\label{fig3:6}
\endminipage\hfill
\minipage{0.49\textwidth}
  \includegraphics[width=\linewidth]{Imagens/figura3-7.jpg}
  \caption{Reconhecimento dos círculos alinhados assimetricamente}\label{fig3:7}
\endminipage
\end{figure}

Ao fim da calibração, o algoritmo retorna a matriz de calibração da câmera, que servirá para remover a distorção radial das imagens capturadas posteriormente; vale frisar que a distorção radial será removida somente se  a matriz de calibração tenha sido calculada corretamente. As Figuras \ref{fig3:8},\ref{fig3:9},\ref{fig3:10} e\ref{fig3:11} mostram mais exemplos da execução do aplicativo para obter \textit{keypoints} bem como imagens da mesma cena sem filtragem de \textit{keypoints}

\begin{figure}[H]
	\centering
		\includegraphics[width= \textwidth]{Imagens/figura3-8.png}
	\caption{Execução do \textit{PhotoGuide} e os \textit{keypoints} filtrados da cena \#1}
	\label{fig3:8}
\end{figure}

\begin{figure}[H]
	\centering
		\includegraphics[width= \textwidth]{Imagens/figura3-10.png}
	\caption{\textit{Keypoints} não filtrados da cena \#1}
	\label{fig3:9}
\end{figure}

\begin{figure}[H]
	\centering
		\includegraphics[width= \textwidth]{Imagens/figura3-9.png}
	\caption{Execução do \textit{PhotoGuide} e os \textit{keypoints} filtrados da cena \#2}
	\label{fig3:10}
\end{figure}

\begin{figure}[H]
	\centering
		\includegraphics[width= \textwidth]{Imagens/figura3-11.png}
	\caption{\textit{Keypoints} não filtrados da cena \#2}
	\label{fig3:11}
\end{figure}


É possível perceber a importância de se detectar e remover falsos positivos, ou \textit{outliers}, já que essa quantidade de pontos errôneos afetaria drasticamente o processamento.

\subsection{Dificuldades Encontradas}

Durante o desenvolvimento do \textit{PhotoGuide}, certos problemas causaram grande dificuldade para a continuação de sua implementação. A ausência de documentação, bem como o tamanho pequeno da comunidade de desenvolvimento utilizando \textit{OpenCV} no \textit{Android} dificultam a pesquisa por casos semelhantes ou para a procura de auxílio com o código fonte, bem como a questão de que a maior parte dos resultados encontrados são escritos para a linguagem \textit{C++}, que é mais permissiva do que \textit{Java}®, a linguagem utilizada no desenvolvimento do \textit{PhotoGuide}. Outros problemas provenientes disso são as diferenças entre implementações, já que em \textit{C++}, é possível realizar diversas operações entre os tipos de \textit{Mat},  que é uma estrutura do \textit{OpenCV} para armazenar informações acerca de uma matriz, fato que não é possível em \textit{Java} já que os diferentes objetos \textit{Mat} na versão do \textit{OpenCV} para \textit{Java} são de classes diferentes e não possuem comportamento semelhante. Para certas tarefas, era possível utilizar o \textit{JNI (Java Native Interface)}\cite{JNI}, que permite que código escrito em \textit{Java }realize chamadas para códigos escritos em linguagens compiladas, como por exemplo \textit{C e C++}, e neste deste trabalho, foi testado algumas implementações do \textit{OpenCV} em \textit{C++}. O \textit{JNI} é utilizado principalmente quando se é necessário utilizar uma biblioteca já implementada em outra linguagem que seja compilada, ou quando a complexidade do código na outra linguagem possui uma menor complexidade. No \textit{PhotoGuide}, não foram encontradas melhorias significativas utilizando \textit{JNI}. 

Outro problema encontrado foi o baixo desempenho, já que a captura constante de quadros junto ao processamento de pares de imagens se mostrou demasiadamente onerosa para serem executados num \textit{smartphone}. Tendo em vista esses problemas, decidimos que apenas a captura de quadros e vídeo fosse feita utilizando a \textit{PSEye}® e posteriormente usando vídeo capturado de \textit{smartphone} e extraído os seus quadros usado um \textit{software} a parte, e o processamento fosse feito numa máquina de maior poder de processamento, como um \textit{desktop} ou \textit{laptop}.

\section{\textit{LSD-SLAM}}

A abordagem seguinte adotada no projeto foi a reconstrução de ambientes utilizando o \textit{LSD-SLAM}. O \textit{LSD-SLAM} é uma ferramenta poderosa porém com pouca documentação, o uso dela se mostra trabalhoso devido ao número grande de parâmetros de configuração possíveis e condições de luz e posição, cada ambiente possui suas próprias configurações otimizadas. A capacidade dessa ferramenta de exportar seus mapas 3D em um tipo de arquivo de fácil leitura faz dela facilmente adaptável para qualquer projeto de navegação 3D e reconhecimento espacial. Aprimoramentos em usabilidade e documentação são desejáveis para futuras versões dessa ferramenta. 

\subsection{Configurações utilizadas}

O \textit{LSD-SLAM} foi testado nas seguintes configurações de máquina, um \textit{desktop} e um \textit{laptop}, respectivamente:

\begin{itemize}
	\item{Processador	\textit{AMD FX™-8350 Eight-Core Processor}, 4000 Mhz, 4 Núcleos, 8 Processadores Lógicos}
	\item{8GB de memória \textit{RAM}}
	\item{Placa gráfica \textit{AMD Radeon R2 260x}}
\end{itemize}

e:

\begin{itemize}
	\item{Processador \textit{Intel® Core™ i3 M370}, 2399 Mhz, 2 Núcleos, 4 Processadores Lógicos}
	\item{4GB de memória \textit{RAM}}
	\item{Placa gráfica integrada: \textit{Intel® HD Graphics}}
\end{itemize}	

\textit{Softwares} e periféricos utilizados:

\begin{itemize}
	\item{\textit{Ubuntu} versão 14.04\cite{Ubuntu}}
	\item{Câmera \textit{PSEye®}, modelo para o \textit{console} \textit{PlayStation®} 3.}
	\item{Câmera embutida no \textit{smartphone Motorola® Moto X Play} 32GB em junção com o aplicativo \textit{OpenCamera} para \textit{Android}.}
	\item{\textit{Software VLC} para extrair os quadros dos vídeos capturados pela câmera.}
	\item{\textit{Software ROS Indigo}.\cite{ROS-Tutorial}}
	\item{\textit{Driver} para \textit{webcam} \texttt{usb\_cam}.\cite{Setup-USBCAM}}
\end{itemize}

No início dos testes com o \textit{LSD-SLAM}, a câmera \textit{Logitech® HD Webcam c270} 
foi utilizada, infelizmente ela não oferecia a capacidade mínima para o \textit{LSD-SLAM}.
 Alguns requisitos para o \textit{LSD-SLAM} são uma taxa mínima de 30 quadros por segundo e
 \textit{global shutter}. \textit{Global shutter} é quando todos os pixels de um quadro são 
 expostos ao mesmo tempo, a \textit{PSEye}® satisfez ambos requisitos e portanto 
 foi utilizada posteriormente no lugar da Logitech.
 
 Um problema encontrado com a utilização da \textit{PSEye}® foi a mobilidade 
 limitada da câmera devido ao fato de que precisava estar conectada via \textit{USB}
 no equipamento usado. Para complementar os testes, foi utilizado o \textit{smartphone}
 \textit{Motorola Moto G X Play}, cuja câmera permite gravar vídeos com 30 quadros por
 segundo e também alta taxa de \textit{bits}. Uma desvantagem é que utiliza \textit{rolling shutter}
 , onde as linhas de pixels são expostas sequencialmente de cima para baixo 
 (comum em câmeras de \textit{bits}). 
 
 A calibração da câmera do \textit{smartphone} foi obtida a partir do PhotoGuide e 
 utilizada como parâmetro para o \textit{LSD-SLAM} usando o método de conversão 
 na seção 3.2.3.7.
 
\subsection{Captura dos \textit{datasets}}

Os \textit{datasets} capturados foram os seguintes:

\begin{itemize}
	\item{Fachada do DCOMP virada para o estacionamento usando a câmera \textit{PSEye®} - 6180 imagens - 119621 pontos}
	\item{Jardim de área residencial usando a câmera \textit{PSEye®} - 660 imagens - 87093 pontos}
	\item{Sala de Mestrado II usando a câmera \textit{PSEye®} - número de imagens desconhecido por ter sido feito usando o \texttt{live\_slam} sem salvar as imagens - 168915 pontos}
	\item{Fachada do DCOMP virada para o estacionamento usando a câmera do \textit{smartphone Motorola® Moto X Play} 32GB- 3280 imagens - 3680087 pontos}
	\item{Corredor interno do 1º andar do DCOMP usando a câmera do \textit{smartphone Motorola® Moto X Play} 32GB - 8319 imagens  - 5877083 pontos}
\end{itemize}

Todos os datasets foram capturados a 30\textit{FPS} com resolução de 640x480.

